@ARTICLE{WEIGERT2017,
    author = {{Weigert}, M. and {Royer}, L. and {Jug}, F. and {Myers}, G.},
    title = "{Isotropic reconstruction of 3D fluorescence microscopy images using convolutional neural networks}",
    journal = {ArXiv e-prints},
    archivePrefix = "arXiv",
    eprint = {1704.01510},
    primaryClass = "cs.CV",
    keywords = {Computer Science - Computer Vision and Pattern Recognition},
    year = 2017,
    month = apr,
    adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170401510W},
    adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@ARTICLE{depth,
   author = {{Simonyan}, K. and {Zisserman}, A.},
    title = "{Very Deep Convolutional Networks for Large-Scale Image Recognition}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1409.1556},
 primaryClass = "cs.CV",
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
     year = 2014,
    month = sep,
   adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1409.1556S},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@InProceedings{unet,
    author="Ronneberger, Olaf
    and Fischer, Philipp
    and Brox, Thomas",
    editor="Navab, Nassir
    and Hornegger, Joachim
    and Wells, William M.
    and Frangi, Alejandro F.",
    title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
    booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
    year="2015",
    publisher="Springer International Publishing",
    address="Cham",
    pages="234--241",
    abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at                                           http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net                                                          .",
    isbn="978-3-319-24574-4"
}

@misc{tensorflow2015-whitepaper,
    title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
    url={https://www.tensorflow.org/},
    note={Software available from tensorflow.org},
    author={
            Mart\'{\i}n~Abadi and
            Ashish~Agarwal and
            Paul~Barham and
            Eugene~Brevdo and
            Zhifeng~Chen and
            Craig~Citro and
            Greg~S.~Corrado and
            Andy~Davis and
            Jeffrey~Dean and
            Matthieu~Devin and
            Sanjay~Ghemawat and
            Ian~Goodfellow and
            Andrew~Harp and
            Geoffrey~Irving and
            Michael~Isard and
            Yangqing Jia and
            Rafal~Jozefowicz and
            Lukasz~Kaiser and
            Manjunath~Kudlur and
            Josh~Levenberg and
            Dan~Man\'{e} and
            Rajat~Monga and
            Sherry~Moore and
            Derek~Murray and
            Chris~Olah and
            Mike~Schuster and
            Jonathon~Shlens and
            Benoit~Steiner and
            Ilya~Sutskever and
            Kunal~Talwar and
            Paul~Tucker and
            Vincent~Vanhoucke and
            Vijay~Vasudevan and
            Fernanda~Vi\'{e}gas and
            Oriol~Vinyals and
            Pete~Warden and
            Martin~Wattenberg and
            Martin~Wicke and
            Yuan~Yu and
            Xiaoqiang~Zheng},
    year={2015},
}

@article{kingma2014adam,
    title={Adam: A method for stochastic optimization},
    author={Kingma, Diederik and Ba, Jimmy},
    journal={arXiv preprint arXiv:1412.6980},
    year={2014}
}

@misc{ferenc-dilated,
    author = {Husz√°r, Ferenc},
    title = {Dilated Convolutions and Kronecker Factored Convolutions},
    type = {Blog},
    number = {May 12th},
    year = {2016},
    howpublished = {\url{http://www.inference.vc/dilated-convolutions-and-kronecker-factorisation/}}
}
